{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76fbaf88-5952-47bf-a68c-85011e49b6de",
   "metadata": {},
   "source": [
    "# Building our First RAG bot - Skill: talk to Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c3b06-c8a0-45db-be9a-974c762ba4b8",
   "metadata": {},
   "source": [
    "We have now all the building blocks to build our first Bot that \"talks with my data\". These blocks are:\n",
    "\n",
    "1) A well indexed hybrid (text and vector) engine with my data in chunks -> Azure AI Search\n",
    "2) A good LLM python framework to build LLM Apps -> LangChain\n",
    "3) Quality OpenAI GPT models that understand language and follow instructions -> GPT3.5 and GPT4\n",
    "4) A persisten memory database -> CosmosDB\n",
    "\n",
    "We are missing just one thing: **Agents**.\n",
    "\n",
    "In this Notebook we introduce the concept of Agents and we use it to build or first RAG bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b64f701d-5b9d-4c7c-b259-c2a515c75961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import asyncio\n",
    "from typing import Dict, List\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField, ConfigurableFieldSpec\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import  GetDocSearchResults_Tool\n",
    "from common.prompts import AGENT_DOCSEARCH_PROMPT\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4163af7-39d0-43b4-8dad-c13108d22a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33836104-822e-4846-8b81-0de8e24838f1",
   "metadata": {},
   "source": [
    "## Introducing: Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc3d38-93f8-4a47-8125-d1bb9f529178",
   "metadata": {},
   "source": [
    "The implementation of Agents is inspired by two papers: the [MRKL Systems](https://arxiv.org/abs/2205.00445) paper (pronounced â€˜miracleâ€™ ðŸ˜‰) and the [ReAct](https://arxiv.org/abs/2210.03629) paper.\n",
    "\n",
    "Agents are a way to leverage the ability of LLMs to understand and act on prompts. In essence, an Agent is an LLM that has been given a very clever initial prompt. The prompt tells the LLM to break down the process of answering a complex query into a sequence of steps that are resolved one at a time.\n",
    "\n",
    "Agents become really cool when we combine them with â€˜expertsâ€™, introduced in the MRKL paper. Simple example: an Agent might not have the inherent capability to reliably perform mathematical calculations by itself. However, we can introduce an expert - in this case a calculator, an expert at mathematical calculations. Now, when we need to perform a calculation, the Agent can call in the expert rather than trying to predict the result itself. This is actually the concept behind [ChatGPT Pluggins](https://openai.com/blog/chatgpt-plugins).\n",
    "\n",
    "In our case, in order to solve the problem \"How do I build a smart bot that talks to my data\", we need this REACT/MRKL approach, in which we need to instruct the LLM that it needs to use 'experts/tools' in order to read/load/understand/interact with a any particular source of data.\n",
    "\n",
    "Let's create then an Agent that interact with the user and uses a Tool to get the information from the Search engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7999a06-aff0-4d21-8be7-fe56c70082a8",
   "metadata": {},
   "source": [
    "#### We start first defining the Tool/Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a862366b-ce9e-44f8-9610-84ec568653ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1_name = \"cogsrch-index-files\"\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "index3_name = \"cogsrch-index-books\"\n",
    "indexes = [index1_name, index2_name, index3_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077886c8-c5d0-481d-a5f9-f4becf60e0f9",
   "metadata": {},
   "source": [
    "We have to convert the Retreiver object into a Tool object (\"the expert\"). Check out the Tool `GetDocSearchResults_Tool` in `utils.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c6ca7-d93b-4961-b90a-08572cad78d8",
   "metadata": {},
   "source": [
    "Declare the tools the agent will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a0fd3a0-527c-42e3-a092-46e03d33bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "topK=7\n",
    "tools = [GetDocSearchResults_Tool(indexes=indexes, k=5, reranker_th=1, sas_token=os.environ['BLOB_SAS_TOKEN'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cac295-8be5-4803-8342-6d4e48cd2294",
   "metadata": {},
   "source": [
    "Get the prompt to use `AGENT_DOCSEARCH_PROMPT` - you can modify this in `prompts.py`! Check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44f8df6-a68e-4215-99f3-10119f796c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = AGENT_DOCSEARCH_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ddf18-3f3c-44b4-8af5-1437973da010",
   "metadata": {},
   "source": [
    "Define the LLM to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aaaf7f5-ef26-48d8-868d-b53aa4c4f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 1500\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True).configurable_alternatives(\n",
    "    ConfigurableField(id=\"model\"),\n",
    "    default_key=\"gpt35\",\n",
    "    gpt4=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d527c12-4e18-4f3f-a9ec-8dab4f9ca7b2",
   "metadata": {},
   "source": [
    "Construct the OpenAI Tools agent.\n",
    "> OpenAI API has deprecated functions in favor of tools. The difference between the two is that the tools API allows the model to request that multiple functions be invoked at once, which can reduce response times in some architectures. Itâ€™s recommended to use the tools agent for OpenAI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fff2766-defb-45fc-b271-3c811077076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm.with_config(configurable={\"model\": \"gpt35\"}), tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338336d9-a64a-4602-908a-742b418e4520",
   "metadata": {},
   "source": [
    "Create an agent executor by passing in the agent and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6c156f-9a17-4daa-80de-70ce2f55063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a017c-3b36-43ab-8633-78f4f005d166",
   "metadata": {},
   "source": [
    "Give it memory - since AgentExecutor is also a Runnable class, we do the same with did on Notebook 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c013314-afe6-4218-b179-d0f7312d2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
    "    cosmos = CosmosDBChatMessageHistory(\n",
    "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "        session_id=session_id,\n",
    "        user_id=user_id\n",
    "        )\n",
    "\n",
    "    # prepare the cosmosdb instance\n",
    "    cosmos.prepare_cosmos()\n",
    "    return cosmos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df017f-3ab7-4943-adc1-3477badf3d3e",
   "metadata": {},
   "source": [
    "Because cosmosDB needs two fields (an id and a partition), and RunnableWithMessageHistory takes by default only one identifier for memory (session_id), we need to use `history_factory_config` parameter and define the multiple keys for the memory class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf93758f-da3b-48fb-9882-91fe327b1751",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_spec = ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        )\n",
    "session_id = ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d1aaa6-efca-4512-b680-896dae39a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[userid_spec,session_id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05c6b489-3db9-4965-9eae-ed2790e62bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'session469', 'user_id': 'user580'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure the session id and user id\n",
    "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
    "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
    "\n",
    "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3295c54e-a5e2-46f6-99fc-6f76453a877d",
   "metadata": {},
   "source": [
    "Run the Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ac81763-6bcc-4408-9daf-d047a0e2cb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 196 ms, sys: 10.3 ms, total: 206 ms\n",
      "Wall time: 4.42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"Hi, I'm Pablo Marin. What's yours\",\n",
       " 'history': [],\n",
       " 'output': \"I'm Jarvis, your assistant. How can I help you today, Pablo Marin?\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "agent_with_chat_history.invoke({\"question\": \"Hi, I'm Pablo Marin. What's yours\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb3fca7e-33a1-40f1-afb0-dee441a1d1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Markov Chains:**\n",
       "\n",
       "Markov chains are mathematical systems that transition from one state to another in a probabilistic manner. The transition from the current state to the next state depends only on the current state and not on the sequence of events that preceded it. This memoryless property makes Markov chains a powerful tool for modeling stochastic processes where the future state is determined by the present state alone.\n",
       "\n",
       "**Application in Medicine:**\n",
       "\n",
       "Markov chains find various applications in medicine, particularly in modeling disease progression, treatment outcomes, and healthcare resource allocation. Here are some key applications:\n",
       "\n",
       "1. **Disease Progression Modeling:** Markov chains are used to model the progression of diseases over time, considering different states such as healthy, diseased, or recovered. These models help in predicting the likelihood of transitioning between states and estimating the impact of interventions or treatments on disease progression<sup><a href=\"https://medicalresearch.org/article1.pdf?s=diseaseprogression&category=modeling&sort=asc&page=1\" target=\"_blank\">[1]</a></sup>.\n",
       "\n",
       "2. **Treatment Outcomes:** In healthcare, Markov models are employed to simulate the long-term effects of different treatment strategies on patient outcomes. By incorporating probabilities of treatment success, relapse, or adverse events, these models aid in decision-making processes for selecting optimal treatment pathways<sup><a href=\"https://healthcareanalysis.org/article2.html?s=treatmentoutcomes&category=modeling&sort=asc\" target=\"_blank\">[2]</a></sup>.\n",
       "\n",
       "3. **Healthcare Resource Allocation:** Markov chains assist in optimizing resource allocation within healthcare systems. By analyzing patient flows, disease prevalence, and treatment effectiveness, these models help in determining the most efficient allocation of healthcare resources such as hospital beds, medical staff, and equipment<sup><a href=\"https://healthcaremanagement.org/article3.csv?s=resourceallocation&category=optimization&sort=asc&page=1\" target=\"_blank\">[3]</a></sup>.\n",
       "\n",
       "4. **Clinical Decision Support:** Markov models are integrated into clinical decision support systems to provide evidence-based recommendations for patient care. These models consider patient-specific factors, treatment histories, and predicted outcomes to assist healthcare professionals in making informed decisions<sup><a href=\"https://clinicalresearch.org/article4.pdf?s=clinicaldecisionsupport&category=healthcare&sort=asc&page=1\" target=\"_blank\">[4]</a></sup>.\n",
       "\n",
       "By leveraging the probabilistic nature of Markov chains, the healthcare industry can enhance decision-making processes, improve patient outcomes, and optimize resource utilization in medical settings."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(agent_with_chat_history.invoke(\n",
    "    {\"question\": \"What are markov chains and is there an application in medicine?\"}, \n",
    "    config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c430c456-f390-4319-a3b1-bee19da130cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Markov Chains in Virus Spread Modeling:**\n",
       "\n",
       "Markov chains play a crucial role in modeling the spread of viruses and infectious diseases. By capturing the stochastic nature of transmission dynamics, Markov models provide valuable insights into the progression of epidemics, the effectiveness of control measures, and the impact of interventions. Here are some key aspects of using Markov chains in virus spread modeling:\n",
       "\n",
       "1. **Transmission Dynamics:** Markov chains can represent the transmission dynamics of viruses within populations by defining different states such as susceptible, infected, and recovered. The transitions between these states are governed by transition probabilities that account for factors like contact rates, transmission probabilities, and recovery rates<sup><a href=\"https://virusresearch.org/article5.pdf?s=transmissiondynamics&category=modeling&sort=asc&page=1\" target=\"_blank\">[5]</a></sup>.\n",
       "\n",
       "2. **Epidemic Forecasting:** Markov models are utilized to forecast the spread of viruses and predict the potential size and duration of epidemics. By simulating multiple scenarios based on different parameters and assumptions, these models help in estimating the trajectory of an outbreak and assessing the effectiveness of various containment strategies<sup><a href=\"https://epidemiologystudy.org/article6.html?s=epidemicforecasting&category=modeling&sort=asc\" target=\"_blank\">[6]</a></sup>.\n",
       "\n",
       "3. **Effectiveness of Interventions:** Markov chains enable researchers to evaluate the impact of interventions such as vaccination campaigns, social distancing measures, and quarantine protocols on controlling virus spread. By adjusting transition probabilities to reflect the effects of interventions, these models provide insights into the effectiveness of different control strategies<sup><a href=\"https://publichealthanalysis.org/article7.csv?s=interventioneffectiveness&category=controlstrategies&sort=asc&page=1\" target=\"_blank\">[7]</a></sup>.\n",
       "\n",
       "4. **Spatial and Temporal Analysis:** Markov models can incorporate spatial and temporal dimensions to analyze how viruses spread across different regions and evolve over time. By considering movement patterns, population densities, and environmental factors, these models offer a comprehensive understanding of the spatial dynamics of virus transmission<sup><a href=\"https://spatialanalysis.org/article8.pdf?s=spatialtemporalanalysis&category=virustransmission&sort=asc&page=1\" target=\"_blank\">[8]</a></sup>.\n",
       "\n",
       "Through the application of Markov chains in virus spread modeling, epidemiologists and public health officials can make informed decisions regarding disease control strategies, resource allocation, and outbreak management to mitigate the impact of infectious diseases on populations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    printmd(agent_with_chat_history.invoke(\n",
    "        {\"question\": \"Interesting, Tell me more about the use specifically in the spread of viruses\"},\n",
    "        config=config)[\"output\"])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fd54f71-03c9-4332-885b-0d1df942fa88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You're welcome! If you have any more questions in the future, feel free to ask. Have a great day, Pablo Marin!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(agent_with_chat_history.invoke({\"question\": \"Thhank you!\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149648ba-945d-4e7d-81f7-a8bca2ac87f2",
   "metadata": {},
   "source": [
    "#### Important: there is a limitation of GPT3.5, once we start adding long prompts, and long contexts and thorough answers, or the agent makes multiple searches for multi-step questions, we run out of space!\n",
    "\n",
    "You can minimize this by:\n",
    "- Shorter System Prompt\n",
    "- Smaller chunks (less than the default of 5000 characters)\n",
    "- Reducing topK to bring less relevant chunks\n",
    "\n",
    "However, you ultimately are sacrificing quality to make everything work with GPT3.5 (cheaper and faster model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41787714-73fd-4336-85f2-bec3abb41eda",
   "metadata": {},
   "source": [
    "### Let's add more things we have learned so far: dynamic LLM selection of GPT4 and asyncronous streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1511d2c3-97fe-4232-a560-014d0f157008",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm.with_config(configurable={\"model\": \"gpt4\"}), tools, prompt) # We select now GPT-4\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
    "agent_with_chat_history = RunnableWithMessageHistory(agent_executor,get_session_history,input_messages_key=\"question\", \n",
    "                                                     history_messages_key=\"history\", history_factory_config=[userid_spec,session_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec5b32-6017-44b9-97e7-34ba3695e688",
   "metadata": {},
   "source": [
    "In prior notebooks with use the function `.stream()` of the runnable in order to stream the tokens. However if you need to stream individual tokens from the agent or surface steps occuring within tools, you would need to use a combination of `Callbacks` and `.astream()` OR the new `astream_events` API (beta).\n",
    "\n",
    "Letâ€™s use here the astream_events API to stream the following events:\n",
    "\n",
    "    Agent Start with inputs\n",
    "    Tool Start with inputs\n",
    "    Tool End with outputs\n",
    "    Stream the agent final anwer token by token\n",
    "    Agent End with outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9600a35e-8d2e-43d0-a334-092b2e8b832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Tell me more about your last answer, search again multiple times and provide a deeper explanation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3808fa33-05bb-4f5d-9ab9-7159f6db62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent: AgentExecutor\n",
      "--\n",
      "Starting tool: docsearch with inputs: {'query': 'Markov chains virus spread modeling'}\n",
      "--\n",
      "Starting tool: docsearch with inputs: {'query': 'Markov chains epidemic forecasting'}\n",
      "--\n",
      "Starting tool: docsearch with inputs: {'query': 'Markov chains spatial temporal analysis in virus transmission'}\n",
      "--\n",
      "Starting tool: docsearch with inputs: {'query': 'Markov chains effectiveness of interventions in virus spread'}\n",
      "Done tool: docsearch\n",
      "--\n",
      "Done tool: docsearch\n",
      "--\n",
      "Done tool: docsearch\n",
      "--\n",
      "Done tool: docsearch\n",
      "--\n",
      "Based on the information from the documents, Markov chains are used in various ways to model the spread of viruses and analyze the effectiveness of interventions. Here is a deeper explanation of their use in these contexts:\n",
      "\n",
      "1. **Spatial Markov Chain Models for Virus Spread**:\n",
      "    - A Spatial Markov Chain model represents the spread of viruses by using a graph structure where nodes represent individuals, and edges represent relationships or contacts between them. The likelihood of virus transmission from one person to another depends on the intensity of their contact and is determined by chance. This model can be extended to include different lockdown scenarios, allowing for the analysis of how social distancing and quarantine policies affect the spread of the disease<sup><a href=\"https://arxiv.org/pdf/2004.05635v1.pdf\" target=\"_blank\">[1]</a></sup>.\n",
      "\n",
      "2. **Epidemic Forecasting and Analysis**:\n",
      "    - Markov chains are used to analyze and understand the behavior of pandemics, such as COVID-19. Nonlinear Markov chain models have been proposed to estimate daily new cases and examine the correlation between new cases and the number of deaths. These models help in forecasting the spread of the virus and evaluating the results of different policies quantitatively and visually<sup><a href=\"http://medrxiv.org/cgi/content/short/2020.04.21.20073668v1\" target=\"_blank\">[2]</a></sup>.\n",
      "\n",
      "3. **Effectiveness of Interventions**:\n",
      "    - The effectiveness of non-pharmaceutical interventions (NPIs) like social distancing, quarantine, and testing rates can be evaluated using Markovian random-walk spatial extensions of models like the SIR (Susceptible, Infected, Recovered) model. This approach allows for simulating the spread of COVID-19 in different regions and helps in understanding the impact of these interventions on controlling the epidemic<sup><a href=\"https://doi.org/10.1101/2020.04.12.20062927\" target=\"_blank\">[3]</a></sup>.\n",
      "\n",
      "4. **Spatial-Temporal Analysis**:\n",
      "    - Markov Chain Monte Carlo (MCMC) methods are used to estimate epidemiological parameters and analyze the spatial-temporal evolution of epidemics. These methods can reveal complex behaviors such as the constant scale of spatial spread, fluctuations in the infection rate associated with extreme weather events, and the impact of control measures on the progression of an epidemic<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3998883\" target=\"_blank\">[4]</a></sup>.\n",
      "\n",
      "5. **Modeling Transmission and Control**:\n",
      "    - Comprehensive stochastic spatio-temporal models have been developed to characterize the transmission and control of diseases like SARS. These models combine deterministic/stochastic population-flow models with stochastic temporal models to simulate the spread of the virus and test the effect of control policies<sup><a href=\"https://www.ncbi.nlm.nih.gov/pubmed/17282007\" target=\"_blank\">[5]</a></sup>.\n",
      "\n",
      "6. **Bayesian Phylogeography**:\n",
      "    - Bayesian frameworks for phylogeography are used to infer, visualize, and test hypotheses about the historical dispersal patterns of viruses. This approach involves character mapping in Bayesian software that samples time-scaled phylogenies, allowing for the reconstruction of timed viral dispersal patterns while accommodating phylogenetic uncertainty<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2740835\" target=\"_blank\">[6]</a></sup>.\n",
      "\n",
      "These models and methods provide critical insights into the dynamics of virus spread and the effectiveness of interventions, which are essential for informing public health strategies and responses to epidemics.\n",
      "--\n",
      "Done agent: AgentExecutor\n"
     ]
    }
   ],
   "source": [
    "async for event in agent_with_chat_history.astream_events(\n",
    "    {\"question\": QUESTION}, config=config, version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"AgentExecutor\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"AgentExecutor\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        # print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41bba7-18df-4ab8-b4f6-60368160d348",
   "metadata": {},
   "source": [
    "#### Note: Try to run this last question with GPT3.5 and see how you are going to run out of token space in the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec64bf-fe24-42fc-8dde-4d478f0af21e",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We just built our first RAG BOT!.\n",
    "\n",
    "- We learned that **Agents + Tools are the best way to go about building Bots**. <br>\n",
    "- We converted the Azure Search retriever into a Tool using the function `GetDocSearchResults_Tool` in `utils.py`\n",
    "- We learned about the events API (Beta), one way to stream the answer from agents\n",
    "- We learned that for comprehensive, quality answers we will run out of space with GPT3.5. GPT4 then becomes necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56306506-d53d-4d43-93e2-a9300ed2a3ee",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "\n",
    "Now that we have a bot with one skill (Document Search), let's build more skills!. In the next Notebook, we are going to build an agent that can understand tabular data in csv file and can execute python commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2525a6d-a7cf-4a3f-a77b-e92de7cb407b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
